#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èŒä¸šæ‰èƒ½æ•°æ®é¢„å¤„ç†å·¥å…· - ä¿®å¤æ¨¡ç³ŠåŒ¹é…ç‰ˆæœ¬
ç”¨äºå°†Excelæ–‡ä»¶æˆ–Google Sheetsè½¬æ¢ä¸ºé™æ€ç½‘é¡µå¯ç”¨çš„åŠ å¯†æ•°æ®
"""

import pandas as pd
import json
import re
import argparse
import jieba
import unicodedata
from rapidfuzz import fuzz


class DataProcessor:
    def __init__(self, debug=False):
        self.debug = debug
        self.processed_data = {
            'hashes': {},
            'fuzzy_map': {},
            'reverse_map': {},  # ç”¨äºè°ƒè¯•ï¼Œå®é™…ä¸ä¼šè¾“å‡ºåˆ°å‰ç«¯
            'total_count': 0
        }

    def log(self, *args, **kwargs):
        """ä»…åœ¨ debug æ¨¡å¼ä¸‹è¾“å‡ºæ—¥å¿—"""
        if self.debug:
            print(*args, **kwargs)

    def simple_hash(self, text: str) -> str:
        """ç®€å•å“ˆå¸Œå‡½æ•°ï¼Œä¸JavaScriptç‰ˆæœ¬ä¿æŒä¸€è‡´"""
        # ç»Ÿä¸€å¤§å°å†™ã€å»ç©ºæ ¼ã€Unicode å½’ä¸€åŒ–ï¼ˆNFKCï¼‰
        text = unicodedata.normalize("NFKC", str(text)).lower().strip()
        hash_value = 0
        for char in text:
            char_code = ord(char)
            hash_value = ((hash_value << 5) - hash_value) + char_code
            hash_value = ((hash_value + 0x80000000) % 0x100000000) - 0x80000000
        return str(abs(hash_value))

    def load_from_excel(self, file_path: str, name_column: str = None, status_column: str = None,
                        aliases_column: str = None, fuzzy_column: str = None):
        """ä»Excelæ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            df = pd.read_excel(file_path)
            print(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼š{file_path}")
            print(f"æ•°æ®è¡Œæ•°ï¼š{len(df)}")
            print(f"åˆ—åï¼š{list(df.columns)}")

            if not name_column:
                name_column = self._detect_name_column(df.columns)
            if not status_column:
                status_column = self._detect_status_column(df.columns)
            if not aliases_column:
                aliases_column = self._detect_aliases_column(df.columns)
            if not fuzzy_column:
                fuzzy_column = self._detect_fuzzy_column(df.columns)

            print(f"ä½¿ç”¨åˆ—æ˜ å°„ï¼š")
            print(f"  èŒä¸šåç§°åˆ—ï¼š{name_column}")
            print(f"  çŠ¶æ€åˆ—ï¼š{status_column}")
            print(f"  åˆ«ç§°åˆ—ï¼š{aliases_column}")
            print(f"  æ¨¡ç³Šè¯åˆ—ï¼š{fuzzy_column}")

            self._process_dataframe(df, name_column, status_column, aliases_column, fuzzy_column)

        except Exception as e:
            print(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥ï¼š{e}")
            return False
        return True

    def load_from_google_sheets(self, sheet_url: str, name_column: str = None, status_column: str = None,
                                aliases_column: str = None, fuzzy_column: str = None):
        """ä»Google SheetsåŠ è½½æ•°æ®"""
        try:
            if '/edit' in sheet_url:
                csv_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=').replace('/edit',
                                                                                             '/export?format=csv')
            else:
                csv_url = sheet_url

            df = pd.read_csv(csv_url)
            print(f"æˆåŠŸè¯»å–Google Sheetsï¼š{sheet_url}")
            print(f"æ•°æ®è¡Œæ•°ï¼š{len(df)}")
            print(f"åˆ—åï¼š{list(df.columns)}")

            if not name_column:
                name_column = self._detect_name_column(df.columns)
            if not status_column:
                status_column = self._detect_status_column(df.columns)
            if not aliases_column:
                aliases_column = self._detect_aliases_column(df.columns)
            if not fuzzy_column:
                fuzzy_column = self._detect_fuzzy_column(df.columns)

            print(f"ä½¿ç”¨åˆ—æ˜ å°„ï¼š")
            print(f"  èŒä¸šåç§°åˆ—ï¼š{name_column}")
            print(f"  çŠ¶æ€åˆ—ï¼š{status_column}")
            print(f"  åˆ«ç§°åˆ—ï¼š{aliases_column}")
            print(f"  æ¨¡ç³Šè¯åˆ—ï¼š{fuzzy_column}")

            self._process_dataframe(df, name_column, status_column, aliases_column, fuzzy_column)

        except Exception as e:
            print(f"è¯»å–Google Sheetså¤±è´¥ï¼š{e}")
            return False
        return True

    def _detect_name_column(self, columns) -> str:
        name_keywords = ['åç§°', 'name', 'èŒä¸š', 'job', 'occupation', 'title', 'æ‰èƒ½', 'talent']
        for col in columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in name_keywords):
                return col
        return columns[0] if len(columns) > 0 else None

    def _detect_status_column(self, columns) -> str:
        status_keywords = ['çŠ¶æ€', 'status', 'æƒ…å†µ', 'state', 'å¯ç”¨', 'available']
        for col in columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in status_keywords):
                return col
        for col in columns:
            return col if col != self._detect_name_column(columns) else None
        return None

    def _detect_aliases_column(self, columns) -> str:
        alias_keywords = ['åˆ«ç§°', 'alias', 'aliases', 'åˆ«å', 'alternative', 'å…¶ä»–', 'other']
        for col in columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in alias_keywords):
                return col
        return None

    def _detect_fuzzy_column(self, columns) -> str:
        fuzzy_keywords = ['æ¨¡ç³Šè¯', 'æ¨¡ç³Š', 'fuzzy', 'å…³é”®è¯', 'keyword', 'keywords', 'æ ‡ç­¾', 'tag', 'tags']
        for col in columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in fuzzy_keywords):
                return col
        return None

    def _process_dataframe(self, df: pd.DataFrame, name_column: str, status_column: str, aliases_column: str,
                           fuzzy_column: str):
        processed_count = 0

        for index, row in df.iterrows():
            name = str(row[name_column]).strip() if pd.notna(row[name_column]) else ""
            if not name or name.lower() in ['nan', 'none', '']:
                continue

            status = str(row[status_column]).strip() if status_column and pd.notna(row[status_column]) else "Available"
            status = self._normalize_status(status)

            aliases = []
            if aliases_column and pd.notna(row[aliases_column]):
                aliases_str = str(row[aliases_column]).strip()
                if aliases_str and aliases_str.lower() not in ['nan', 'none', '']:
                    aliases = [alias.strip() for alias in re.split(r'[,ï¼Œ;ï¼›|/]', aliases_str) if alias.strip()]

            fuzzy_keywords = []
            if fuzzy_column and pd.notna(row[fuzzy_column]):
                fuzzy_str = str(row[fuzzy_column]).strip()
                if fuzzy_str and fuzzy_str.lower() not in ['nan', 'none', '']:
                    fuzzy_keywords = [kw.strip() for kw in re.split(r'[,ï¼Œ;ï¼›|/\s]', fuzzy_str) if kw.strip()]

            main_hash = self.simple_hash(name)

            self.processed_data['hashes'][main_hash] = {
                'status': status,
                'aliases': aliases,
                'main_name': name
            }
            self.processed_data['reverse_map'][main_hash] = name

            for alias in aliases:
                if alias == name:
                    continue
                alias_hash = self.simple_hash(alias)
                self.processed_data['hashes'][alias_hash] = {
                    'status': status,
                    'aliases': [],
                    'is_alias': True,
                    'main_name': name
                }
                self.processed_data['reverse_map'][alias_hash] = f"{alias} (åˆ«ç§°: {name})"

            # è°ƒè¯•è¾“å‡º
            self.log(f"å¤„ç† '{name}' çš„æ¨¡ç³Šè¯: {fuzzy_keywords}")
            for fuzzy_kw in fuzzy_keywords:
                fuzzy_hash = self.simple_hash(fuzzy_kw)
                if fuzzy_hash not in self.processed_data['fuzzy_map']:
                    self.processed_data['fuzzy_map'][fuzzy_hash] = []
                if main_hash not in self.processed_data['fuzzy_map'][fuzzy_hash]:
                    self.processed_data['fuzzy_map'][fuzzy_hash].append(main_hash)
                    self.log(f"  æ·»åŠ æ˜ å°„: '{fuzzy_kw}' (hash:{fuzzy_hash}) -> '{name}' (hash:{main_hash})")

            processed_count += 1

        self.processed_data['total_count'] = processed_count
        print(f"âœ… æˆåŠŸå¤„ç† {processed_count} æ¡è®°å½•")

        self._generate_smart_fuzzy_mapping()

    def _normalize_status(self, status: str) -> str:
        status = status.lower()
        if status in ['available', 'å¯ç”¨', 'ç©ºé—²', 'æœªå ç”¨']:
            return 'Available'
        elif status in ['occupied', 'å·²å ç”¨', 'å ç”¨', 'ä½¿ç”¨ä¸­']:
            return 'Occupied'
        elif status in ['hold', 'holding', 'ä¿ç•™', 'é¢„ç•™', 'æš‚åœ']:
            return 'Hold'
        else:
            return 'Available'

    def _generate_smart_fuzzy_mapping(self):
        self.log("ç”Ÿæˆæ™ºèƒ½æ¨¡ç³ŠåŒ¹é…æ˜ å°„...")

        main_names = []
        for hash_key, data in self.processed_data['hashes'].items():
            if not data.get('is_alias', False):
                main_names.append((hash_key, data['main_name']))

        self.log(f"å¤„ç† {len(main_names)} ä¸ªä¸»è¦åç§°")

        for main_hash, main_name in main_names:
            self.log(f"ä¸º '{main_name}' ç”Ÿæˆæ¨¡ç³Šæ˜ å°„")

            name_hash = self.simple_hash(main_name)
            self._add_to_fuzzy_map(name_hash, main_hash, f"å®Œæ•´åç§°: {main_name}")

            try:
                keywords = list(jieba.cut(main_name))
                self.log(f"  jiebaåˆ†è¯ç»“æœ: {keywords}")

                for keyword in keywords:
                    keyword = keyword.strip()
                    if len(keyword) <= 1 or not keyword or keyword.isspace():
                        continue
                    if all(not c.isalnum() for c in keyword):
                        continue
                    keyword_hash = self.simple_hash(keyword)
                    self._add_to_fuzzy_map(keyword_hash, main_hash, f"å…³é”®è¯: {keyword} -> {main_name}")

            except Exception as e:
                self.log(f"  jiebaåˆ†è¯å¤±è´¥: {e}")

            if len(main_name) >= 2:
                for i in range(2, min(len(main_name) + 1, 5)):
                    prefix = main_name[:i]
                    prefix_hash = self.simple_hash(prefix)
                    self._add_to_fuzzy_map(prefix_hash, main_hash, f"å‰ç¼€: {prefix} -> {main_name}")

        self.log(f"ç”Ÿæˆäº† {len(self.processed_data['fuzzy_map'])} ä¸ªæ¨¡ç³ŠåŒ¹é…æ˜ å°„")

    def _add_to_fuzzy_map(self, fuzzy_hash, main_hash, debug_info):
        if fuzzy_hash not in self.processed_data['fuzzy_map']:
            self.processed_data['fuzzy_map'][fuzzy_hash] = []
        if main_hash not in self.processed_data['fuzzy_map'][fuzzy_hash]:
            self.processed_data['fuzzy_map'][fuzzy_hash].append(main_hash)
            self.log(f"    {debug_info}")

    def generate_static_html(self, template_path: str, output_path: str):
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                html_content = f.read()

            data_to_inject = {
                'hashes': self.processed_data['hashes'],
                'fuzzy_map': self.processed_data['fuzzy_map'],
                'total_count': self.processed_data['total_count']
            }

            data_json = json.dumps(data_to_inject, ensure_ascii=False, separators=(',', ':'))

            html_content = html_content.replace(
                'const ENCRYPTED_DATA = {\n            // ç¤ºä¾‹æ•°æ®ç»“æ„ï¼Œå®é™…æ•°æ®ä¼šåœ¨æ„å»ºæ—¶æ³¨å…¥\n            hashes: {\n                // "hash1": { status: "Available", aliases: ["alias1", "alias2"] },\n                // "hash2": { status: "Occupied", aliases: [] }\n            },\n            fuzzy_map: {\n                // "fuzzy_hash1": ["hash1", "hash2"]\n            },\n            total_count: 0\n        };',
                f'const ENCRYPTED_DATA = {data_json};'
            )

            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)

            print(f"âœ… æˆåŠŸç”Ÿæˆé™æ€HTMLæ–‡ä»¶ï¼š{output_path}")
            print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šæ€»è®°å½•æ•° {self.processed_data['total_count']} | å“ˆå¸Œ {len(self.processed_data['hashes'])} | æ¨¡ç³Šæ˜ å°„ {len(self.processed_data['fuzzy_map'])}")

        except Exception as e:
            print(f"ç”Ÿæˆé™æ€HTMLå¤±è´¥ï¼š{e}")
            return False
        return True

    def save_debug_info(self, output_path: str):
        debug_data = {
            'reverse_map': self.processed_data['reverse_map'],
            'fuzzy_map_sample': dict(list(self.processed_data['fuzzy_map'].items())[:20]),
            'total_count': self.processed_data['total_count'],
            'sample_hashes': {k: v for k, v in list(self.processed_data['hashes'].items())[:10]},
            'fuzzy_map_stats': {
                'total_fuzzy_entries': len(self.processed_data['fuzzy_map']),
                'sample_mappings': []
            }
        }

        for fuzzy_hash, main_hashes in list(self.processed_data['fuzzy_map'].items())[:10]:
            debug_data['fuzzy_map_stats']['sample_mappings'].append({
                'fuzzy_hash': fuzzy_hash,
                'mapped_to': [self.processed_data['reverse_map'].get(h, 'unknown') for h in main_hashes]
            })

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(debug_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜è‡³ï¼š{output_path}")
        except Exception as e:
            print(f"ä¿å­˜è°ƒè¯•ä¿¡æ¯å¤±è´¥ï¼š{e}")


def main():
    parser = argparse.ArgumentParser(description='èŒä¸šæ‰èƒ½æ•°æ®é¢„å¤„ç†å·¥å…·')
    parser.add_argument('--excel', type=str, help='Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--sheets', type=str, help='Google Sheets URL')
    parser.add_argument('--template', type=str, default='template.html', help='HTMLæ¨¡æ¿æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default='index.html', help='è¾“å‡ºHTMLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•è¾“å‡º')
    parser.add_argument('--debug-file', type=str, help='æŒ‡å®šè°ƒè¯•ä¿¡æ¯è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--name-col', type=str, help='èŒä¸šåç§°åˆ—å')
    parser.add_argument('--status-col', type=str, help='çŠ¶æ€åˆ—å')
    parser.add_argument('--aliases-col', type=str, help='åˆ«ç§°åˆ—å')
    parser.add_argument('--fuzzy-col', type=str, help='æ¨¡ç³Šè¯åˆ—å')

    args = parser.parse_args()

    if not args.excel and not args.sheets:
        print("é”™è¯¯ï¼šå¿…é¡»æŒ‡å®š --excel æˆ– --sheets å‚æ•°")
        return

    processor = DataProcessor(debug=args.debug)

    if args.excel:
        if not processor.load_from_excel(args.excel, args.name_col, args.status_col, args.aliases_col, args.fuzzy_col):
            return
    elif args.sheets:
        if not processor.load_from_google_sheets(args.sheets, args.name_col, args.status_col, args.aliases_col,
                                                 args.fuzzy_col):
            return

    if not processor.generate_static_html(args.template, args.output):
        return

    if args.debug:
        debug_file = args.debug_file or args.output.replace('.html', '_debug.json')
        processor.save_debug_info(debug_file)

    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“„ é™æ€ç½‘é¡µå·²ç”Ÿæˆï¼š{args.output}")
    if args.debug:
        print(f"ğŸ” è°ƒè¯•æ•°æ®å·²ä¿å­˜ï¼š{debug_file}")


if __name__ == '__main__':
    main()
